# -*- coding: utf-8 -*-
"""TP1_AAA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-rm4_QRGr14nw19IdhO7EeLgw9SvUIMu

<p><img alt="Colaboratory logo" height="45px" src="/img/colab_favicon.ico" align="left" hspace="10px" vspace="0px"></p>

<h1>Qu'est-ce que Colaboratory ?</h1>

Colaboratory, souvent raccourci en "Colab", vous permet d'écrire et d'exécuter du code Python dans votre navigateur. Il offre les avantages suivants :
- Aucune configuration requise
- Accès gratuit aux GPU
- Partage facile

Que vous soyez <strong>étudiant</strong>, <strong>data scientist</strong> ou <strong>chercheur en IA</strong>, Colab peut vous simplifier la tâche. Regardez la <a href="https://www.youtube.com/watch?v=inN8seMm7UI">présentation de Colab</a> pour en savoir plus ou commencez tout de suite.
"""

#



import time
from keras.utils import np_utils
from keras.models import Sequential

from keras.optimizer_v1 import SGD

from keras.layers import Input, Dense, Activation
from keras.layers import Input, Dense, Flatten, Concatenate, Conv1D, Activation
#from keras.layers.normalization import BatchNormalization
from keras.layers import BatchNormalization  
from keras.layers import 
from sklearn.datasets import load_breast_cancer
from sklearn import preprocessing



data=load_breast_cancer()

data

data.data
X=data.data

import numpy as np
np.shape(X)

y= data.target

np.shape(y)

def normalized(x) :
  return (x- np.mean(x,axis=0))/(np.max(x, axis=0)-np.min(x, axis=0))

x_nom = normalized(X)

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x_nom, y, test_size=0.3, train_size=0.7, random_state=True)

x_train, x_test, y_train, y_test = train_test_split(x_nom, y, test_size=0.3, train_size=0.7, random_state=True)

np.shape(x_train), np.shape(y_train)

learning_rate = 0.8
batch_size = 50
nb_epoch = 50

model=Sequential()
model.add(Dense(1, input_dim=30))
model.add(Activation('sigmoid'))

sgd = SGD(learning_rate)

model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1)

from keras.layers import  Dropout
learning_rate = 0.2
batch_size = 50
nb_epoch = 100

model=Sequential()

model.add(Dense(128, input_dim=30))
model.add(Activation('sigmoid'))
model.add(Dropout(0.3))
model.add(Dense(512))
model.add(Activation('sigmoid'))
model.add(Dropout(0.3))

model.add(Dense(1024))
model.add(Activation('sigmoid'))
model.add(Dropout(0.3))

model.add(Dense(1))
model.add(Activation('softmax'))

sgd = SGD(learning_rate)

model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1)

#

from keras.callbacks import ModelCheckpoint, EarlyStopping
learning_rate = 0.2
batch_size = 50
nb_epoch = 100

model=Sequential()

model.add(Dense(128, input_dim=30))
model.add(Activation('sigmoid'))
model.add(Dropout(0.3))

model.add(BatchNormalization())

model.add(Dense(512))
model.add(Activation('sigmoid'))
model.add(Dropout(0.3))
model.add(BatchNormalization())

#model.add(Dense(1024))
#model.add(Activation('sigmoid'))
#model.add(Dropout(0.3))

model.add(Dense(1))
model.add(Activation('softmax'))

checkpointer = ModelCheckpoint(filepath="NN_TP1.hdfs", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='min', period=1)

early= EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')


sgd = SGD(learning_rate)

model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1)



"""## <strong>Premiers pas</strong>

Le document que vous consultez n'est pas une page Web statique, mais un environnement interactif appelé <strong>notebook Colab</strong>, qui vous permet d'écrire et d'exécuter du code.

Voici par exemple une <strong>cellule de code</strong> avec un bref script en Python qui calcule une valeur, l'enregistre dans une variable et imprime le résultat :
"""

seconds_in_a_day = 24 * 60 * 60
seconds_in_a_day

"""Pour exécuter le code dans la cellule ci-dessus, sélectionnez-le en cliquant dessus, puis cliquez sur le bouton de lecture à gauche du code ou utilisez le raccourci clavier Commande/Ctrl+Entrée. Pour modifier le code, cliquez simplement sur la cellule.

Les variables que vous définissez dans une cellule peuvent être utilisées par la suite dans d'autres cellules :
"""

seconds_in_a_week = 7 * seconds_in_a_day
seconds_in_a_week

"""Les notebooks Colab vous permettent d'utiliser, dans un même document, du <strong>code exécutable</strong>, du <strong>texte enrichi</strong>, des <strong>images</strong>, du code <strong>HTML</strong>, du code <strong>LaTeX</strong> et bien plus. Lorsque vous créez des notebooks Colab, ils sont enregistrés dans votre compte Google Drive. Vous pouvez facilement les partager avec vos collaborateurs ou vos amis, qui peuvent alors y apporter des commentaires ou même les modifier. Pour en savoir plus, consultez la page <a href="/notebooks/basic_features_overview.ipynb">Présentation de Colaboratory</a>. Pour créer un notebook Colab, utilisez le menu "Fichier" ci-dessus ou le lien <a href="http://colab.research.google.com#create=true">Créer un notebook Colab</a>.

Les notebooks Colab sont des notebooks Jupyter hébergés par Colab. Pour en savoir plus sur le projet Jupyter, consultez le site Web <a href="https://www.jupyter.org">jupyter.org</a>.

## Science des données

Colab vous permet de tirer pleinement parti des bibliothèques populaires Python pour analyser et visualiser des données. La cellule de code ci-dessous utilise <strong>numpy</strong> pour générer des données aléatoires et <strong>matplotlib</strong> pour les visualiser. Pour modifier le code, cliquez simplement sur la cellule.
"""

import numpy as np
from matplotlib import pyplot as plt

ys = 200 + np.random.randn(100)
x = [x for x in range(len(ys))]

plt.plot(x, ys, '-')
plt.fill_between(x, ys, 195, where=(ys > 195), facecolor='g', alpha=0.6)

plt.title("Sample Visualization")
plt.show()

"""Vous pouvez importer vos propres données dans les notebooks Colab depuis votre compte Google Drive, y compris depuis des feuilles de calcul, ainsi que depuis GitHub et de nombreuses autres sources. Pour en savoir plus sur l'importation de données et l'utilisation de Colab dans le domaine de la science des données, consultez les liens ci-dessous dans la section <a href="#working-with-data">Utiliser les données</a>.

## Machine learning

Colab vous permet d'importer un ensemble de données d'images, d'entraîner un classificateur d'images sur cet ensemble et d'évaluer le modèle, tout cela avec <a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb">quelques lignes de code</a>. Les notebooks Colab exécutent ce code sur les serveurs cloud de Google. Vous avez donc à votre disposition toute la puissance du matériel Google, y compris les <a href="#using-accelerated-hardware">GPU et TPU</a>, quelle que soit la puissance de votre ordinateur. Vous n'avez besoin que d'un navigateur.

Colab est très largement utilisé par la communauté du machine learning, par exemple dans les applications suivantes :
- Premiers pas avec TensorFlow
- Développement et entraînement de réseaux de neurones
- Expérimentation avec les TPU
- Dissémination de la recherche en IA
- Création de tutoriels

Pour voir comment les notebooks Colab sont utilisés dans des applications de machine learning, reportez-vous aux <a href="#machine-learning-examples">exemples de machine learning</a> ci-dessous.

## Autres ressources

### Utiliser les notebooks dans Colab
- [Présentation de Colaboratory](/notebooks/basic_features_overview.ipynb)
- [Guide de Markdown](/notebooks/markdown_guide.ipynb)
- [Importer des bibliothèques et installer des dépendances](/notebooks/snippets/importing_libraries.ipynb)
- [Enregistrer et charger des notebooks dans GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)
- [Formulaires interactifs](/notebooks/forms.ipynb)
- [Widgets interactifs](/notebooks/widgets.ipynb)
- <img src="/img/new.png" height="20px" align="left" hspace="4px" alt="New"></img>
 [TensorFlow 2 dans Colab](/notebooks/tensorflow_version.ipynb)

<a name="working-with-data"></a>
### Utiliser les données
- [Chargement de données : Drive, Sheets et Google Cloud Storage](/notebooks/io.ipynb) 
- [Graphiques : visualiser les données](/notebooks/charts.ipynb)
- [Premiers pas avec BigQuery](/notebooks/bigquery.ipynb)

### Cours d'initiation au Machine Learning
Vous trouverez ci-dessous quelques-uns des notebooks de la formation Google en ligne sur le machine learning. Consultez la <a href="https://developers.google.com/machine-learning/crash-course/">formation complète en ligne</a> pour en savoir plus.
- [Présentation du DataFrame pandas](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)
- [Régression linéaire avec tf.keras et des données synthétiques](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)


<a name="using-accelerated-hardware"></a>
### Utiliser le matériel accéléré
- [TensorFlow avec des GPU](/notebooks/gpu.ipynb)
- [TensorFlow avec des TPU](/notebooks/tpu.ipynb)

<a name="machine-learning-examples"></a>

## Exemples de machine learning

Pour voir des exemples complets d'analyses interactives de machine learning rendues possibles par Colaboratory, consultez ces tutoriels utilisant des modèles issus de <a href="https://tfhub.dev">TensorFlow Hub</a>.

Voici quelques exemples :

- <a href="https://tensorflow.org/hub/tutorials/tf2_image_retraining">Recyclage d'un classificateur d'images</a> : construisez un modèle Keras sur un classificateur d'images pré-entraîné pour faire la distinction entre différentes fleurs.
- <a href="https://tensorflow.org/hub/tutorials/tf2_text_classification">Classification de texte</a> : classez des avis sur des films provenant de la base de données IMDB comme <em>positifs</em> ou <em>négatifs</em>.
- <a href="https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization">Transfert de style</a> : utilisez le deep learning pour transférer un style d'une image à une autre.
- <a href="https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa">Questions/Réponses sur l'encodeur de phrases universel multilingue</a> : utilisez un modèle de machine learning afin de répondre aux questions issues de l'ensemble de données SQuAD.
- <a href="https://tensorflow.org/hub/tutorials/tweening_conv3d">Interpolation vidéo</a> : prédisez ce qui s'est passé entre la première et la dernière image d'une vidéo.
"""

import keras
import numpy as np
from keras.datasets import mnist
from keras.layers import Dense, Dropout, Flatten
from keras.models import Sequential

(x_train, y_train), (x_test, y_test) = mnist.load_data()



np.shape(x_train)

np.shape(y_train)

y_train[0]

np.shape(x_test)

np.shape(y_test)

import matplotlib.pyplot as plt

plt.figure(figsize=(7.195,3.841), dpi=100)

for i in range(100):
  plt.subplot(10,10,i+1)
  plt.imshow(x_train[i].reshape([28,28]), cmap='gray')
  plt.axis('off')

x_train = x_train.reshape(60000, 28*28)
x_test = x_test.reshape(10000, 28*28)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')


x_train /= 255
x_test /= 255

from keras.layers import Input, Dense, Activation
from keras.optimizer_v1 import SGD

learning_rate = 0.8

batch_size = 30
nb_epoch = 50


model = Sequential()
model.add(Dense(30, input_dim=784))

model.add(Activation('sigmoid'))

#model.add(Dense(128, activation='relu'))
#model.add(Dropout(0.5))


model.add(Dense(1, activation='sigmoid'))


sgd= SGD(learning_rate)

model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1)

#tp CNN 24/11/2021

import keras
import numpy as np
from keras.datasets import mnist
from keras.layers import Dense, Dropout, Flatten
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
from keras import optimizers

(x_train, y_train), (x_test, y_test) = mnist.load_data()

rows, cols, channels = 28,28,1

x_train = x_train.reshape(60000, rows, cols, channels)
x_test = x_test.reshape(10000, rows, cols, channels)


x_train = x_train.astype('float32')
x_test = x_test.astype('float32')


x_train /= 255
x_test /= 255

print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

np.shape(x_train)

model = Sequential()

model.add(Conv2D(32,kernel_size=(3, 3),activation='relu', input_shape=(28,28,1)))
model.add(Conv2D(64,(3, 3),activation='relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))



model.add(Flatten())


model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(10, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy, optimizer='Adadelta', metrics=['accuracy'])

model.summary()